Title: GOMIL: Global Optimization of Multiplier by Integer Linear Programming

Year: 2021

Abstract: Multiplier is an important arithmetic circuit. State-of-the-art designs consist of a partial product generator (PPG), a compressor tree (CT), and a carry propagation adder (CPA), with the last two components dominating the area and delay. Existing representative works optimize the CT and the CPA separately, adding a rigid boundary between these two components. In this paper, we break the boundary by proposing GOMIL, a global optimization for multiplier by integer linear programming. Two ILP sub-problems are first formulated to optimize the CT and the prefix structure in the CPA, respectively. Then, they are unified to provide a global optimization to the multiplier. The proposed method is applicable to not only multipliers with the AND gate-based PPG, but also those with Booth encoding-based PPG. The experimental results showed that the multipliers optimized by GOMIL can reduce the power-delay product by up to 71%, compared to the state-of-the-art multipliers developed in industry. The code of GOMIL is made open-source.

Keywords: Multiplier optimizations

Summary: It formulates the multiplier optimization problem as two sub ILP problems and proposes a global multiplier optimization strategy based on the formulation.


Title: RL-MUL: Multiplier Design Optimization with Deep Reinforcement Learning

Year: 2023

Abstract: Multiplication is a fundamental operation in many applications, and multipliers are widely adopted in various circuits. However, optimizing multipliers is challenging and non-trivial due to the huge design space. In this paper, we propose RL-MUL, a multiplier design optimization framework based on reinforcement learning. Specifically, we utilize matrix and tensor representations for the compressor tree of a multiplier, based on which the convolutional neural networks can be seamlessly incorporated as the agent network. The agent can learn to adjust the multiplier structure based on a Pareto-driven reward which is customized to accommodate the trade-off between area and delay. Experiments are conducted on different bit widths of multipliers. The results demonstrate that the multipliers produced by RL-MUL dominate all baseline designs in terms of both area and delay. The performance gain of RL-MUL is further validated by comparing the area and delay of processing element arrays using multipliers from RL-MUL and baseline approaches.

Keywaords: Multiplier optimization

Summary: It formulates the multiplier design and leverages RL to optimize the multiplier design.

Title: PrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning

Year: 2022

Abstract: In this work, we present a reinforcement learning (RL) based approach to designing parallel prefix circuits such as adders
or priority encoders that are fundamental to high-performance digital design. Unlike prior methods, our approach designs solutions tabula rasa
purely through learning with synthesis in the loop.We design a grid-based state-action representation and an RL environment for constructing legal prefix circuits. Deep Convolutional RL agents trained on this environment produce prefix adder circuits that Pareto-dominate existing baselines with up to 16.0% and 30.2% lower area for the same delay in the 32b and 64b settings respectively. We observe that agents trained with open-source synthesis tools and cell library can design adder circuits that achieve lower area and delay than commercial tool adders in an industrial cell library.

Keywords: prefix circuit optimization

Summary: It presents a parallel prefix circuit optimization with reinforcement learning.


Title: Multiplier Optimization via E-Graph Rewriting

Year: 2023

Abstract: Multiplier circuits account for significant resource
usage in datapath-dominated circuit designs, and RTL designers
continue to build bespoke hand-crafted multiplication arrays for
their particular application. The construction of an optimized
multiplier presents trade-offs between pre-processing to generate
a smaller array and array reduction. A data structure known as
an e-graph has recently been applied to datapath optimization,
where the e-graph’s ability to efficiently explore trade-offs has
been shown to be crucial. We propose an e-graph based rewriting
framework to construct optimized multiplier circuits. Such a
framework can express alternative multiplier representations and
generate customized circuit designs. We demonstrate that the
proposed tool, which we call OptiMult, can reduce the latency
of a squarer by up to 46% and reduce the latency of a standard
multiplier by up to 9% when compared against logic synthesis
instantiated components.

Keywords: multiplier optimization

Summary: It leverages e-graph rewriting to optimize the multiplier circuit designs.


Title: Understanding the Effects of Permanent Faults in GPU’s Parallelism Management and Control Units

Year: 2023

Abstract: Modern Graphics Processing Units (GPUs) demand life expectancy
extended to many years, exposing the hardware to aging (i.e., permanent
faults arising after the end-of-manufacturing test). Hence,
techniques to assess permanent fault impacts in GPUs are strongly
required, especially in safety-critical domains.
This paper presents a method to evaluate permanent faults in the
GPU’s scheduler and control units, together with the first figures to
quantify these effects. We inject 5.83x105 permanent faults in the
gate-level units of a GPU model. Then, we map the observed error
categories as software errors by instrumenting 13 applications and
two convolutional neural networks, injecting more than 1.65x105
permanent errors (1,000 errors per application), reducing evaluation
times from several years to hundreds of hours. Our results highlight
that faults in GPU parallelism management units impact software
execution parameters. Moreover, errors in resource management or
instructions codes hang the code, while 45% of errors induce silent
data corruption.

Keywords: GPU reliability, permanent faults

Summary: It evaluates permanent faults in the GPU's scheduler and control units, and analyzes the influence on GPU reliability.

Title: From RTL to CUDA: A GPU Acceleration Flow for RTL Simulation with Batch Stimulus

Year: 2022

Abstract: High-throughput RTL simulation is critical for verifying today’s
highly complex SoCs. Recent research has explored accelerating
RTL simulation by leveraging event-driven approaches or partitioning
heuristics to speed up simulation on a single stimulus. To further
accelerate throughput performance, industry-quality functional verification
signoff must explore running multiple stimulus (i.e., batch
stimulus) simultaneously, either with directed tests or random inputs.
In this paper, we propose RTLFlow, a GPU-accelerated RTL
simulation flow with batch stimulus. RTLflow first transpiles RTL
into CUDA kernels that each simulates a partition of the RTL simultaneously
across multiple stimulus. It also leverages CUDA Graph
and pipeline scheduling for efficient runtime execution. Measuring
experimental results on a large industrial design (NVDLA) with
65536 stimulus, we show that RTLflow running on a single A6000
GPU can achieve a 40× runtime speed-up when compared to an
80-thread multi-core CPU baseline.

Keywords: RTL to CUDA, GPU acceleration

Summary: This work presents a GPU based RTL simulation acceleration framework. It particularly explores batch simulation to make best use of GPUs.


Title: Pathfinding Future PIM Architectures by Demystifying a Commercial PIM Technology

Year: 2024

Abstract: Processing-in-memory (PIM) has been explored for
decades by computer architects, yet it has never seen the light of
day in real-world products due to its high design overheads and
lack of a killer application. With the advent of critical memoryintensive
workloads, several commercial PIM technologies have
been introduced to the market, ranging from domain-specific PIM
architectures to more general-purpose PIM architectures. In this
work, we deepdive into UPMEM’s commercial PIM technology,
a general-purpose PIM-enabled parallel computing architecture
that is highly programmable. Our first key contribution is the
development of a flexible simulation framework for PIM. The
simulator we developed (aka uPIMulator) enables the compilation
of UPMEM-PIM source codes into its compiled machine-level
instructions, which are subsequently consumed by our cyclelevel
performance simulator. Using uPIMulator, we demystify
UPMEM’s PIM design through a detailed characterization study.
Finally, we identify some key limitations of the current UPMEMPIM
system through our case studies and present some important
architectural features that will become critical for future PIM
architectures to support.

Keywords: UPMem, performance analysis, Commercial PIM

Summary: This work mainly explores the use of UPMEM with a set of representative micro benchmarks and analyzes the pros and cons of upmem from the perspective of parallel processing acceleration.


Title:

Year:

Abstract:

Keywords:

Summary:



Title:

Year:

Abstract:

Keywords:

Summary:


Title:

Year:

Abstract:

Keywords:

Summary:


Title:

Year:

Abstract:

Keywords:

Summary:
